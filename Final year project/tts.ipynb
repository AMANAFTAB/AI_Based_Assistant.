{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip instal cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import nltk\n",
    "# from nltk.corpus import cmudict\n",
    "\n",
    "# nltk.download('cmudict')  # Download CMU Pronouncing Dictionary (one-time)\n",
    "\n",
    "# cmudict = cmudict.dict()\n",
    "\n",
    "# def preprocess_text(text):\n",
    "# #   \"\"\"\n",
    "# #   Preprocesses text for text-to-speech conversion, including:\n",
    "\n",
    "# #   - Lowercasing\n",
    "# #   - Punctuation removal\n",
    "# #   - Text normalization (e.g., replacing abbreviations with full words)\n",
    "# #   - Phoneme conversion using CMU Pronouncing Dictionary\n",
    "\n",
    "# #   Args:\n",
    "# #       text (str): Input text.\n",
    "\n",
    "# #   Returns:\n",
    "# #       str: Preprocessed text, encoded as a sequence of phonemes.\n",
    "# #   \"\"\"\n",
    "\n",
    "#   # Lowercase for consistency\n",
    "#   text = text.lower()\n",
    "\n",
    "#   # Remove punctuation\n",
    "#   text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "#   # Text normalization (replace with your specific rules if needed)\n",
    "#   text = text.replace('&', 'and')  # Example normalization\n",
    "\n",
    "#   # Phoneme conversion using CMU Pronouncing Dictionary\n",
    "#   phonemes = []\n",
    "#   for word in text.split():\n",
    "#     if word in cmudict:\n",
    "#       phonemes.extend(cmudict[word][0])  # Get first pronunciation\n",
    "#     else:\n",
    "#       phonemes.append('UNKNOWN')  # Handle unknown words\n",
    "\n",
    "#   return ' '.join(phonemes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchtext.datasets import TextMELD  # Assuming TextMELD dataset used for training\n",
    "\n",
    "# # Replace with paths to your pre-trained weights (adapt if using different models)\n",
    "# TACOTRON2_WEIGHTS = 'path/to/tacotron2_weights.pt'\n",
    "# MELGAN_WEIGHTS = 'path/to/melgan_weights.pt'\n",
    "\n",
    "# class Tacotron2MelGAN:\n",
    "#   # \"\"\"\n",
    "#   # Wrapper class for Tacotron 2 and MelGAN, performing text-to-speech conversion.\n",
    "\n",
    "#   # Attributes:\n",
    "#   #     tacotron2 (torch.nn.Module): Pre-trained Tacotron 2 model.\n",
    "#   #     melgan (torch.nn.Module): Pre-trained MelGAN model.\n",
    "#   #     text_scaler (torch.nn.Module): Optional text scaler if used during training.\n",
    "#   # \"\"\"\n",
    "\n",
    "#   def __init__(self, tacotron2_weights, melgan_weights, text_scaler=None):\n",
    "#     self.tacotron2 = torch.load(tacotron2_weights)\n",
    "#     self.tacotron2.eval()  # Set to evaluation mode\n",
    "#     self.melgan = torch.load(melgan_weights)\n",
    "#     self.melgan.eval()  # Set to evaluation mode\n",
    "#     self.text_scaler = text_scaler\n",
    "\n",
    "#   def infer(self, text):\n",
    "#     # \"\"\"\n",
    "#     # Converts text to speech using Tacotron 2 and MelGAN.\n",
    "\n",
    "#     # Args:\n",
    "#     #     text (str): Input text.\n",
    "\n",
    "#     # Returns:\n",
    "#     #     torch.Tensor: Generated audio waveform.\n",
    "#     # \"\"\"\n",
    "\n",
    "#     phonemes = preprocess_text(text)  # Preprocess text\n",
    "\n",
    "#     # Text scaling (if applicable based on training process)\n",
    "#     if self.text_scaler is not None:\n",
    "#       phonemes = self.text_scaler(torch.tensor([phonemes]))\n",
    "\n",
    "#     # Implement forward pass through Tacotron 2 and MelGAN (replace with your model's logic)\n",
    "#     with torch.no_grad():\n",
    "#       # Assuming your Tacotron 2 model takes phonemes as input:\n",
    "#       mel_spectrogram, *_ = self.tacotron2(phonemes)\n",
    "#       audio = self.melgan(mel_spectrogram)\n",
    "\n",
    "#     return audio\n",
    "\n",
    "# # Example usage (assuming TextMELD dataset used for training)\n",
    "# def tts_tacotron2(text):\n",
    "#   # Load pre-trained models and potentially text scaler (if used during training)\n",
    "#   tacotron2_melgan = Tacotron2MelGAN(TACOTRON2_WEIGHTS, MELGAN_WEIGHTS)\n",
    "\n",
    "#   audio = tacotron2_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/huggingface/parler-tts.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 00:18:09.668035: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-06 00:18:10.039682: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 00:18:11.048701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/root/anaconda3/envs/final_year/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/final_year/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Using the model-agnostic default `max_length` (=2580) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "Calling `sample` directly is deprecated and will be removed in v4.41. Use `generate` or a custom generation loop instead.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_227195/2933386963.py\", line 17, in <module>\n",
      "    generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/parler_tts/modeling_parler_tts.py\", line 2608, in generate\n",
      "    outputs = self.sample(\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2584, in sample\n",
      "    return self._sample(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2730, in _sample\n",
      "    logger.warning_once(\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: '`eos_token_id` is deprecated in this function and will be removed in v4.41, use `stopping_criteria=StoppingCriteriaList([EosTokenCriteria(eos_token_id=eos_token_id)])` instead. Otherwise make sure to set `model.generation_config.eos_token_id`'\n",
      "Arguments: (<class 'FutureWarning'>,)\n",
      "/root/anaconda3/envs/final_year/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "import soundfile as sf\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler_tts_mini_v0.1\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler_tts_mini_v0.1\")\n",
    "\n",
    "prompt = \"The trip is going great! The family has been on some amazing adventures together, from camping and renovating their home to participating in a community clean-up day and attending a school talent show. They've also been making memories together through games, gardening, and a family reunion. It seems like they're having a wonderful time bonding and creating new experiences together.\"\n",
    "description = \"A mature male voice with a slight British accent, speaking in a professional hospital setting.\"\n",
    "\n",
    "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "audio_arr = generation.cpu().numpy().squeeze()\n",
    "sf.write(\"parler_tts_out.wav\", audio_arr, model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
