{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7e29b0-76b1-4d80-bf19-41657e34367b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Plain_llm_with_rag.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 09:37:46.161445: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-06 09:37:46.355864: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 09:37:47.053475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/root/anaconda3/envs/final_year/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import Plain_llm_with_rag\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM, pipeline\n",
    "import soundfile as sf\n",
    "from playsound import playsound\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "import wave\n",
    "import tempfile\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a765a9-88b3-4c67-9fa9-a6cf124230f2",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58708d60-e952-4af7-bbd7-e1b0e67c12c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5213540ef4814bcd8f5cee956bcc0d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Loaded\n"
     ]
    }
   ],
   "source": [
    "obj = Plain_llm_with_rag.Rag_Llama(context_window=4096,\n",
    "                max_new_tokens=256,\n",
    "                generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
    "                system_prompt=\"\"\"\"\"\",\n",
    "                tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "                model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "                device_map=\"cuda:0\",\n",
    "                model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True})\n",
    "\n",
    "query_engine = obj.call(\"How did the camping trip go?\",\n",
    "                        embedding_model = \"sentence-transformers/all-mpnet-base-v2\", \n",
    "                        data_path = \"./data\", \n",
    "                        first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59082b02-e786-47fd-971c-46810d990171",
   "metadata": {},
   "source": [
    "# Speech To text Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931009dd-04de-4bc0-b73a-29c3250c5aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"small\"  # medium is better \n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0d256a-8911-4dd2-9812-c18d5e0d98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path=\"parler_tts_out.wav\"\n",
    "beam_size = 5  # You can adjust the beam size as needed\n",
    "segments, info = model.transcribe(audio_path, beam_size=beam_size)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a649859-46c0-4d1b-b293-676b95bc624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The trip is going great.\n",
      " The family has been on some amazing adventures together, from camping and renovating their\n",
      " home to participating in a community, clean up day, and attending a school talent show.\n",
      " They've also been making memories together through games, gardening, and a family reunion.\n",
      " It seems like they're having a wonderful time bonding and creating new experiences\n",
      " together.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\n",
    "for segment in segments:\n",
    "    prompt = segment.text\n",
    "    # print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ba68f-f10c-430b-8a55-850ea5d2914e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a3aa380-9fe8-4ec8-8ffa-605278b28803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment_Analysis:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_sentiment_model(self, task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None):\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "        # self.model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "        self.classifier = pipeline(task=task, model=model, top_k=top_k)\n",
    "        return self.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e8edf9-65c7-4b5d-807f-4e769bcd7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_obj = Sentiment_Analysis()\n",
    "sentiment_model = sentiment_obj.load_sentiment_model(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065d8c40-e54f-49a8-bf9a-949aee889a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_sentiment(prompt, sentiment_model):\n",
    "        sentences = [prompt]\n",
    "        \n",
    "        model_outputs = sentiment_model(sentences)\n",
    "        return model_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e747d4-6270-4371-80b1-248184b9f252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.9616066217422485},\n",
       " {'label': 'approval', 'score': 0.02113819681107998},\n",
       " {'label': 'realization', 'score': 0.006704954896122217},\n",
       " {'label': 'annoyance', 'score': 0.004398947115987539},\n",
       " {'label': 'admiration', 'score': 0.004183753859251738},\n",
       " {'label': 'joy', 'score': 0.0033300661016255617},\n",
       " {'label': 'excitement', 'score': 0.0027510200161486864},\n",
       " {'label': 'disappointment', 'score': 0.002710954053327441},\n",
       " {'label': 'disapproval', 'score': 0.0025487258099019527},\n",
       " {'label': 'sadness', 'score': 0.002413568552583456},\n",
       " {'label': 'optimism', 'score': 0.0022420785389840603},\n",
       " {'label': 'confusion', 'score': 0.002063870895653963},\n",
       " {'label': 'love', 'score': 0.002022828906774521},\n",
       " {'label': 'anger', 'score': 0.0019361290615051985},\n",
       " {'label': 'caring', 'score': 0.0016462838975712657},\n",
       " {'label': 'amusement', 'score': 0.0015497974818572402},\n",
       " {'label': 'fear', 'score': 0.0015286715934053063},\n",
       " {'label': 'disgust', 'score': 0.0014189083594828844},\n",
       " {'label': 'desire', 'score': 0.001355486805550754},\n",
       " {'label': 'gratitude', 'score': 0.0011681781616061926},\n",
       " {'label': 'curiosity', 'score': 0.0010797700379043818},\n",
       " {'label': 'surprise', 'score': 0.000792524719145149},\n",
       " {'label': 'embarrassment', 'score': 0.000527350464835763},\n",
       " {'label': 'relief', 'score': 0.0005217842408455908},\n",
       " {'label': 'nervousness', 'score': 0.0004884983645752072},\n",
       " {'label': 'pride', 'score': 0.00046811497304588556},\n",
       " {'label': 'grief', 'score': 0.00046800138079561293},\n",
       " {'label': 'remorse', 'score': 0.0004151073517277837}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_list = call_sentiment(prompt, sentiment_model)\n",
    "sentiment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1319abba-e895-4baa-b0c7-e0aea5b396cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {\n",
    "    'joy': 0.0,\n",
    "    'excitement': 0.0,\n",
    "    'optimism': 0.0,\n",
    "    'love': 0.0,\n",
    "    'amusement': 0.0,\n",
    "    'gratitude': 0.0,\n",
    "    'surprise': 0.0,\n",
    "    'relief': 0.0,\n",
    "    'pride': 0.0,\n",
    "    'neutral': 0.0,\n",
    "    'approval': 0.0,\n",
    "    'realization': 0.0,\n",
    "    'admiration': 0.0,\n",
    "    'caring': 0.0,\n",
    "    'curiosity': 0.0,\n",
    "    'embarrassment': 0.0,\n",
    "    'nervousness': 0.0,\n",
    "    'sadness': 0.0,\n",
    "    'disappointment': 0.0,\n",
    "    'confusion': 0.0,\n",
    "    'disapproval': 0.0,\n",
    "    'fear': 0.0,\n",
    "    'desire': 0.0,\n",
    "    'grief': 0.0,\n",
    "    'remorse': 0.0,\n",
    "    'annoyance': 0.0,\n",
    "    'anger': 0.0,\n",
    "    'disgust': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf29f39e-d261-4beb-9847-8710ff36de45",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_ids = {\n",
    "    'joy': 0,\n",
    "    'excitement': 1,\n",
    "    'optimism': 2,\n",
    "    'love': 3,\n",
    "    'amusement': 4,\n",
    "    'gratitude': 5,\n",
    "    'surprise': 6,\n",
    "    'relief': 7,\n",
    "    'pride': 8,\n",
    "    'neutral': 9,\n",
    "    'approval': 10,\n",
    "    'realization': 11,\n",
    "    'admiration': 12,\n",
    "    'caring': 13,\n",
    "    'curiosity': 14,\n",
    "    'embarrassment': 15,\n",
    "    'nervousness': 16,\n",
    "    'sadness': 17,\n",
    "    'disappointment': 18,\n",
    "    'confusion': 19,\n",
    "    'disapproval': 20,\n",
    "    'fear': 21,\n",
    "    'desire': 22,\n",
    "    'grief': 23,\n",
    "    'remorse': 24,\n",
    "    'annoyance': 25,\n",
    "    'anger': 26,\n",
    "    'disgust': 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27177640-926e-4ff1-9759-670d7dbb8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = 0.0\n",
    "\n",
    "for senti in sentiment_list:\n",
    "    emotions[senti['label']] = round(senti['score'], 4)\n",
    "\n",
    "    if emotions[senti['label']] > max_:\n",
    "        max_ = emotions[senti['label']]\n",
    "        max_emotion = emotion_ids[senti['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8176a02-d500-475e-8996-13f3d96bd328",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_list = []\n",
    "for i in emotions:\n",
    "    normal_list.append(emotions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab558abb-b9f2-44c5-b09f-5676dada3d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65cb7d9c-ea55-43ae-ab16-8a01fa2bfa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "df_list.append(dt_string)\n",
    "for i in normal_list:\n",
    "    df_list.append(i)\n",
    "df_list.append(max_emotion)\n",
    "\n",
    "if max_emotion < 9:\n",
    "    outcome = 0.5 + (0.055 * (9 - max_emotion))\n",
    "else:\n",
    "    outcome = 0.5 - (0.027 * (max_emotion - 9))\n",
    "df_list.append(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d085c5-dd7f-4301-9697-672f6ca4ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.read_pickle('emotion_time_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a327cd80-6951-45da-b41c-83b2e3216eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d13ae496-871d-48f2-a17e-48d72fb7a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.loc[len(pre_df)] = df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9d9f30f-4208-404b-8560-474a26ab77c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdd30e36-3f6f-46d9-8326-a5fa44a478f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.to_pickle('emotion_time_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47ce507f-11fc-4a9c-8439-89a0f0d87166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>joy</th>\n",
       "      <th>excitement</th>\n",
       "      <th>optimism</th>\n",
       "      <th>love</th>\n",
       "      <th>amusement</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>surprise</th>\n",
       "      <th>relief</th>\n",
       "      <th>pride</th>\n",
       "      <th>...</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>fear</th>\n",
       "      <th>desire</th>\n",
       "      <th>grief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>emotion</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-15 01:00:00</th>\n",
       "      <td>3/15/24 1:0:0</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15 01:00:00</th>\n",
       "      <td>3/15/24 1:0:0</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15 01:00:00</th>\n",
       "      <td>3/15/24 1:0:0</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15 01:00:00</th>\n",
       "      <td>3/15/24 1:0:0</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15 01:00:00</th>\n",
       "      <td>3/15/24 1:0:0</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date_time     joy  excitement  optimism    love  \\\n",
       "date_time                                                                  \n",
       "2024-03-15 01:00:00  3/15/24 1:0:0  0.0680      0.0238    0.0411  0.0508   \n",
       "2024-03-15 01:00:00  3/15/24 1:0:0  0.0800      0.0649    0.0393  0.0385   \n",
       "2024-03-15 01:00:00  3/15/24 1:0:0  0.0709      0.0403    0.0065  0.0333   \n",
       "2024-03-15 01:00:00  3/15/24 1:0:0  0.0755      0.0214    0.0326  0.0695   \n",
       "2024-03-15 01:00:00  3/15/24 1:0:0  0.0595      0.0209    0.0218  0.0264   \n",
       "\n",
       "                     amusement  gratitude  surprise  relief   pride  ...  \\\n",
       "date_time                                                            ...   \n",
       "2024-03-15 01:00:00     0.0376     0.0446    0.0545  0.0217  0.0516  ...   \n",
       "2024-03-15 01:00:00     0.0153     0.0386    0.0752  0.0526  0.0354  ...   \n",
       "2024-03-15 01:00:00     0.0454     0.0299    0.0009  0.0050  0.0561  ...   \n",
       "2024-03-15 01:00:00     0.0551     0.0579    0.0488  0.0121  0.0166  ...   \n",
       "2024-03-15 01:00:00     0.0006     0.0319    0.0414  0.0417  0.0424  ...   \n",
       "\n",
       "                     disapproval    fear  desire   grief  remorse  annoyance  \\\n",
       "date_time                                                                      \n",
       "2024-03-15 01:00:00       0.0261  0.0564  0.0508  0.0387   0.0324     0.0282   \n",
       "2024-03-15 01:00:00       0.0199  0.0175  0.0537  0.0011   0.0506     0.0223   \n",
       "2024-03-15 01:00:00       0.0247  0.0019  0.0406  0.0048   0.0103     0.0706   \n",
       "2024-03-15 01:00:00       0.0130  0.0259  0.0720  0.0020   0.0710     0.0231   \n",
       "2024-03-15 01:00:00       0.0336  0.0569  0.0120  0.0474   0.0046     0.0120   \n",
       "\n",
       "                      anger  disgust  emotion  outcome  \n",
       "date_time                                               \n",
       "2024-03-15 01:00:00  0.0124   0.0304        0      0.0  \n",
       "2024-03-15 01:00:00  0.0542   0.0228        0      1.0  \n",
       "2024-03-15 01:00:00  0.0491   0.0653        0      0.0  \n",
       "2024-03-15 01:00:00  0.0668   0.0555        0      0.0  \n",
       "2024-03-15 01:00:00  0.0083   0.0528        0      1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc6b535-658d-4e71-a538-f3acc7ef3cb3",
   "metadata": {},
   "source": [
    "# Query for a response from the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "375e948d-dd80-4113-8acc-d62fe625edc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The family members worked together to achieve their goals, whether it was\\nparticipating in a talent show, completing a fitness challenge, gardening competition, family\\nreunion, camping trip, home renovation project, surprise birthday party, community clean-up\\nday, fishing expedition, or family game night. They supported and encouraged each other,\\nsharing their skills and talents to create a harmonious and enjoyable experience for all.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=Plain_llm_with_rag.get_response(prompt, query_engine)\n",
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a37254f-1f89-4f55-8dd9-b43d7355965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"small\"  # medium is better \n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39569a1c-1e85-4f25-ae21-ad71c0a1a45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler_tts_mini_v0.1\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler_tts_mini_v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ceecfd8-9c3a-4d60-a48f-7452cd1abcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = response.response\n",
    "description = \"A mature male voice with a slight British accent, speaking in a professional hospital setting.\"\n",
    "\n",
    "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "857f6a08-e13e-4b48-9622-73ed55522003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the model-agnostic default `max_length` (=2580) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "Calling `sample` directly is deprecated and will be removed in v4.41. Use `generate` or a custom generation loop instead.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_244805/2514317604.py\", line 1, in <module>\n",
      "    generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/parler_tts/modeling_parler_tts.py\", line 2608, in generate\n",
      "    outputs = self.sample(\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2584, in sample\n",
      "    return self._sample(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2730, in _sample\n",
      "    logger.warning_once(\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: '`eos_token_id` is deprecated in this function and will be removed in v4.41, use `stopping_criteria=StoppingCriteriaList([EosTokenCriteria(eos_token_id=eos_token_id)])` instead. Otherwise make sure to set `model.generation_config.eos_token_id`'\n",
      "Arguments: (<class 'FutureWarning'>,)\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f01a0af9240>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/final_year/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generation \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_input_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m audio_arr \u001b[38;5;241m=\u001b[39m generation\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      3\u001b[0m sf\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparler_tts_out.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m, audio_arr, model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msampling_rate)\n",
      "File \u001b[0;32m~/anaconda3/envs/final_year/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/final_year/lib/python3.10/site-packages/parler_tts/modeling_parler_tts.py:2608\u001b[0m, in \u001b[0;36mParlerTTSForConditionalGeneration.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, synced_gpus, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   2600\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2601\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2602\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2603\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2604\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2605\u001b[0m     )\n\u001b[1;32m   2607\u001b[0m     \u001b[38;5;66;03m# 12. run sample\u001b[39;00m\n\u001b[0;32m-> 2608\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2609\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2624\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot incompatible mode for generation, should be one of greedy or sampling. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2625\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsure that beam search is de-activated by setting `num_beams=1` and `num_beam_groups=1`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2626\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/final_year/lib/python3.10/site-packages/transformers/generation/utils.py:2584\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2580\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m   2581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling `sample` directly is deprecated and will be removed in v4.41. Use `generate` or a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom generation loop instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2583\u001b[0m     )\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/final_year/lib/python3.10/site-packages/transformers/generation/utils.py:2804\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2801\u001b[0m next_token_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;66;03m# pre-process distribution\u001b[39;00m\n\u001b[0;32m-> 2804\u001b[0m next_token_scores \u001b[38;5;241m=\u001b[39m \u001b[43mlogits_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_token_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2805\u001b[0m next_token_scores \u001b[38;5;241m=\u001b[39m logits_warper(input_ids, next_token_scores)\n\u001b[1;32m   2807\u001b[0m \u001b[38;5;66;03m# Store scores, attentions and hidden_states when required\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/final_year/lib/python3.10/site-packages/transformers/generation/logits_process.py:98\u001b[0m, in \u001b[0;36mLogitsProcessorList.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         scores \u001b[38;5;241m=\u001b[39m processor(input_ids, scores, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/envs/final_year/lib/python3.10/site-packages/transformers/generation/logits_process.py:220\u001b[0m, in \u001b[0;36mMinNewTokensLengthLogitsProcessor.__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m    218\u001b[0m scores_processed \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    219\u001b[0m vocab_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], device\u001b[38;5;241m=\u001b[39mscores\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 220\u001b[0m eos_token_id \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m eos_token_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39misin(vocab_tensor, eos_token_id)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_tokens_length \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_new_tokens:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "audio_arr = generation.cpu().numpy().squeeze()\n",
    "sf.write(\"parler_tts_out.mp3\", audio_arr, model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782cf38b-6348-4dc0-a8d6-8679ed24d0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d79ef-d97b-4ae2-99d5-8b57017b868f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
